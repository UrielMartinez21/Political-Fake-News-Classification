{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch                    # Install the PyTorch library for deep learning.\n",
    "!pip install --upgrade transformers   # Install and upgrade the Transformers library for NLP tasks.\n",
    "!pip install pandas                   # Install the Pandas library for data manipulation.\n",
    "!pip install scikit-learn             # Install scikit-learn for machine learning tasks.\n",
    "!pip install sentencepiece            # Install SentencePiece for text tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer archivos de drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Montar Google Drive en /content/drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Listar archivos en el directorio raíz de Google Drive\n",
    "!ls '/content/drive/MyDrive/proyecto_nlp/modelo/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas necesarias\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Fecha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El juez del caso Villarejo abre una pieza secr...</td>\n",
       "      <td>La investigación trata de esclarecer si la ene...</td>\n",
       "      <td>20/12/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El PSOE se une al PP para rechazar en el Congr...</td>\n",
       "      <td>Unidas Podemos vuelve a quedarse solo en la me...</td>\n",
       "      <td>14/06/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El Gobierno evita valorar los detalles de la c...</td>\n",
       "      <td>La portavoz del Ejecutivo, Isabel Rodríguez, s...</td>\n",
       "      <td>08/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>Casi siete mil afiliados refrendan la candidat...</td>\n",
       "      <td>La presidenta de la Comunidad de Madrid contin...</td>\n",
       "      <td>09/05/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID</td>\n",
       "      <td>1</td>\n",
       "      <td>El rey de Arabia Saudí y el presidente de Turq...</td>\n",
       "      <td>Erdogan y Bin Abdelaziz resaltaron la importan...</td>\n",
       "      <td>20/10/2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Label                                             Titulo   \n",
       "0  ID      1  El juez del caso Villarejo abre una pieza secr...  \\\n",
       "1  ID      1  El PSOE se une al PP para rechazar en el Congr...   \n",
       "2  ID      1  El Gobierno evita valorar los detalles de la c...   \n",
       "3  ID      1  Casi siete mil afiliados refrendan la candidat...   \n",
       "4  ID      1  El rey de Arabia Saudí y el presidente de Turq...   \n",
       "\n",
       "                                         Descripcion       Fecha  \n",
       "0  La investigación trata de esclarecer si la ene...  20/12/2019  \n",
       "1  Unidas Podemos vuelve a quedarse solo en la me...  14/06/2022  \n",
       "2  La portavoz del Ejecutivo, Isabel Rodríguez, s...  08/03/2022  \n",
       "3  La presidenta de la Comunidad de Madrid contin...  09/05/2022  \n",
       "4  Erdogan y Bin Abdelaziz resaltaron la importan...  20/10/2018  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leer archivos train\n",
    "train_uno = pd.read_csv(\"../dataset/D21000_train.csv\", delimiter=\";\")\n",
    "train_dos = pd.read_csv(\"../dataset/D46000_train.csv\", delimiter=\";\")\n",
    "\n",
    "# Unir conjuntos\n",
    "df = pd.concat([train_uno, train_dos], ignore_index=True)\n",
    "\n",
    "# Ver df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto es para que los resultados sean reproducibles\n",
    "seed = 26                                           # La semilla que queramos\n",
    "random.seed(seed)                                   # Fijamos la semilla para random\n",
    "np.random.seed(seed)                                # Fijamos la semilla para numpy (usado por pandas)\n",
    "torch.manual_seed(seed)                             # Fijamos la semilla para torch\n",
    "torch.cuda.manual_seed_all(seed)                    # Fijamos la semilla para cuda (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar rasgos y etiquetas\n",
    "X = df[[\"Titulo\", \"Descripcion\", \"Fecha\"]]\n",
    "y = df[\"Label\"]\n",
    "\n",
    "# Separar la informacion en conjuntos de entrenamiento y evaluacion\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"[+] Conjunto de train: {len(X_train)}\")\n",
    "print(f\"[+] Conjunto de test: {len(X_eval)}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"[+]Total de datos: {len(X_train) + len(X_eval)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizador de Roberta\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"PlanTL-GOB-ES/roberta-base-bne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar el conjunto de entrenamiento\n",
    "train_encodings = tokenizer(\n",
    "    X_train[\"Titulo\"].tolist(),             # Lista de titulos\n",
    "    X_train[\"Descripcion\"].tolist(),        # Lista de descripciones\n",
    "    X_train[\"Fecha\"].tolist(),              # Lista de fechas\n",
    "    padding=\"max_length\",                   # Rellenar las secuencias hasta la longitud maxima\n",
    "    truncation='only_second',               # Si la noticia excede la longitud maxima, se truncara el segundo campo\n",
    "    max_length=128,                         # Longitud maxima de las secuencias\n",
    "    return_tensors=\"pt\"                     # Devolver los tensores de PyTorch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar el conjunto de evaluacion\n",
    "eval_encodings = tokenizer(                 # Mismo procedimiento que para el conjunto de entrenamiento\n",
    "    X_eval[\"Titulo\"].tolist(),\n",
    "    X_eval[\"Descripcion\"].tolist(),\n",
    "    X_eval[\"Fecha\"].tolist(),\n",
    "    padding=\"max_length\",\n",
    "    truncation='only_second',               # Si la noticia excede la longitud maxima, se truncara el segundo campo\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar las entradas codificadas a variables separadas\n",
    "train_input_ids = train_encodings[\"input_ids\"]\n",
    "train_attention_masks = train_encodings[\"attention_mask\"]\n",
    "\n",
    "eval_input_ids = eval_encodings[\"input_ids\"]\n",
    "eval_attention_masks = eval_encodings[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear TensorDatasets para entrenamiento y evaluacion\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, torch.tensor(y_train.tolist()))\n",
    "eval_dataset = TensorDataset(eval_input_ids, eval_attention_masks, torch.tensor(y_eval.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataLoaders para cargar los datos en lotes\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo pre-entrenado\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"PlanTL-GOB-ES/roberta-base-bne\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el optimizador y el dispositivo de entrenamiento\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)  # Add weight decay for L2 regularization 0.1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar la tasa de dropout\n",
    "dropout_rate = 0.1                              # Esto para que sea facil cambiarlo\n",
    "model.classifier.dropout.p = dropout_rate       # Configurar la tasa de dropout para la capa de clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de entrenamiento\n",
    "model.train()\n",
    "\n",
    "best_mcc = -1.0                                                   # Best MCC value\n",
    "best_epoch = -1                                                   # Epoch where the best MCC was achieved\n",
    "best_model_path = \"/content/drive/MyDrive/proyecto_nlp/modelo/\"   # Path to save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    print(f\"[+]Epoca {epoch + 1}\")\n",
    "    total_train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    total_batches = len(train_dataloader)\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_dataloader, 1):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_masks, labels = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        logits = outputs.logits\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "        correct_predictions += (predicted_labels == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calcular el porcentaje de avance\n",
    "        progress_percentage = (batch_idx / total_batches) * 100\n",
    "\n",
    "        # Imprimir el porcentaje de avance\n",
    "        print(f\"\\rIteración {batch_idx}/{total_batches} - Avance: {progress_percentage:.2f}%\", end=\"\")\n",
    "\n",
    "\n",
    "    train_loss = total_train_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    # Evaluation on the evaluation set\n",
    "    model.eval()\n",
    "\n",
    "    print(\"\\n[+]Evaluando el modelo...\")\n",
    "    with torch.no_grad():\n",
    "        total_eval_loss = 0.0\n",
    "        eval_predictions = []\n",
    "        eval_labels = []\n",
    "\n",
    "        total_eval_batches = len(eval_dataloader)\n",
    "\n",
    "        for eval_batch_idx, eval_batch in enumerate(eval_dataloader, 1):\n",
    "            eval_batch = tuple(t.to(device) for t in eval_batch)\n",
    "            input_ids, attention_masks, labels = eval_batch\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            eval_predictions.extend(predicted_labels.tolist())\n",
    "            eval_labels.extend(labels.tolist())\n",
    "\n",
    "            # Calcular el porcentaje de avance en la evaluación\n",
    "            eval_progress_percentage = (eval_batch_idx / total_eval_batches) * 100\n",
    "\n",
    "            # Imprimir el porcentaje de avance en la evaluación\n",
    "            print(f\"\\rEvaluación - Iteración {eval_batch_idx}/{total_eval_batches} - Avance: {eval_progress_percentage:.2f}%\", end=\"\")\n",
    "\n",
    "        eval_loss = total_eval_loss / len(eval_dataloader)\n",
    "        eval_accuracy = accuracy_score(eval_labels, eval_predictions)\n",
    "        eval_f1 = f1_score(eval_labels, eval_predictions)\n",
    "        eval_recall = recall_score(eval_labels, eval_predictions)\n",
    "        eval_mcc = matthews_corrcoef(eval_labels, eval_predictions)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Eval Loss: {eval_loss:.4f} | Eval Accuracy: {eval_accuracy:.4f}\")\n",
    "    print(f\"Eval F1: {eval_f1:.4f}\")\n",
    "    print(f\"Eval Recall: {eval_recall:.4f}\")\n",
    "    print(f\"Eval MCC: {eval_mcc:.4f}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    # --------------------------------------| Guardado del mejor modelo |-------------------------------------- #\n",
    "    # Guardar el modelo si se consigue un MCC mayor\n",
    "    if eval_mcc > best_mcc:\n",
    "        model.save_pretrained(best_model_path)\n",
    "        tokenizer.save_pretrained(best_model_path)\n",
    "        best_mcc = eval_mcc\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "# --------------------------------------| Resultados finales |-------------------------------------- #\n",
    "print(\"Best model achieved at epoch:\", best_epoch)\n",
    "print(\"Best evaluation MCC:\", best_mcc)\n",
    "print(\"Model saved at:\", best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, matthews_corrcoef\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "seed = 26\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the pre-trained model and tokenizer\n",
    "model_path = \"/content/drive/MyDrive/DATASET/YourSavedModel\"\n",
    "tokenizer_path = \"/content/drive/MyDrive/DATASET/YourSavedModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model and tokenizer\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "# Load new data from a CSV file\n",
    "new_data_path = \"/content/drive/MyDrive/DATASET/D11000_test.csv\"\n",
    "new_df = pd.read_csv(new_data_path, delimiter=';')\n",
    "\n",
    "# Set batch size for inference\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the new data\n",
    "new_encodings = tokenizer(\n",
    "    new_df[\"Titulo\"].tolist(),\n",
    "    new_df[\"Descripcion\"].tolist(),\n",
    "    new_df[\"Fecha\"].tolist(),\n",
    "    padding=\"max_length\",\n",
    "    truncation='only_second',\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "new_input_ids = new_encodings[\"input_ids\"]\n",
    "new_attention_masks = new_encodings[\"attention_mask\"]\n",
    "\n",
    "# Create a TensorDataset and DataLoader for the new data\n",
    "new_dataset = TensorDataset(new_input_ids, new_attention_masks)\n",
    "new_dataloader = DataLoader(new_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Use GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Perform inference on the new data\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in new_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_masks = batch\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_masks)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "        predictions.extend(predicted_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true labels from the new data\n",
    "true_labels = new_df[\"Label\"].tolist()\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "recall = recall_score(true_labels, predictions)\n",
    "mcc = matthews_corrcoef(true_labels, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"MCC: {mcc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
